{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DigitalTechSummit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntonBaumannDE/detectron2_DTS19/blob/master/DigitalTechSummit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9ayxeTfPEp0",
        "colab_type": "text"
      },
      "source": [
        "# Overview\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtu7kAfbgnEw",
        "colab_type": "text"
      },
      "source": [
        "**Instance and Keypoint Segmentation on the same Video.**\n",
        "\n",
        "**Notebook was made during the Digital Tech Summit Hackathon in 2019.**\n",
        "\n",
        "At the time of the Hackathon Detectron2 was just released a few hours ago. I thought it'd be a cool idea to play around with both, instance and keypoint segmentation in the same video. This Notebook allows you to create some awesome visualizations for your custom videos.  \n",
        "\n",
        "How to use it: \n",
        "\n",
        "1.   Mount your Google Drive so you can import your videos (Just run the first code snippet)\n",
        "2.   Define your directories and run everything\n",
        "3.   Put the frames back into a video\n",
        "\n",
        "As soon as I have some spare time I will have to fix the different color variations in each frame.\n",
        "You could solve this by enabling H.264 encoding for ffmpeg and to compile openCV in the Colab runtime. Detectron has a separate visualizer for videos, which would allow the user to run inference on videos much easier and faster than I did during the hackathon.  \n",
        "\n",
        "\n",
        "Many thanks to Yuxin Wu for taking the time to answer my questions and for setting up this decent tutorial on colab: https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5\n",
        "\n",
        "\n",
        "//Anton"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhDP5ym6ouv4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#Define some input paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZLwwqQaDLLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ0R-X3e-vU9",
        "colab_type": "text"
      },
      "source": [
        "**Let's define the directories so we can load our custom *video*:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWYjuB-KWWld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "inputpath = str('/content/drive/My Drive/video.mp4')                              #Path to the video you want to be processed\n",
        "storagepath = str('/content/drive/My Drive/Colab Notebooks/Frames')\n",
        "outputpath = str('/content/drive/My Drive/Colab Notebooks/finalGripper')\n",
        "os.mkdir(storagepath)                                                             #make a folder for storing all the frames after Instance Segmentation\n",
        "os.mkdir(outputpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdgQQj6-nDZ0",
        "colab_type": "text"
      },
      "source": [
        "# Install Detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YPf5euiPBb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U torch torchvision\n",
        "import torch, torchvision\n",
        "torch.__version__\n",
        "!pip install git+https://github.com/facebookresearch/fvcore.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwZw33icTaic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
        "!pip install -e detectron2_repo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPmd0pbJUvFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlzI7Pd6ba-z",
        "colab_type": "text"
      },
      "source": [
        "# Instance Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u_QUXxEbUNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap = cv2.VideoCapture(inputpath)\n",
        "if (cap.isOpened()== False): \n",
        "  print(\"Error opening video stream or file\")\n",
        "frame_width = int(cap.get(4))\n",
        "frame_height = int(cap.get(3))\n",
        "\n",
        "import numpy as np\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"./detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5                                      # set threshold for this model\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"\n",
        "predictor = DefaultPredictor(cfg)\n",
        "import numpy as np\n",
        "i=0\n",
        "while(i<300):                                                                    #Video with up to 300 frames gets segmented into each frame\n",
        "  ret, frame = cap.read()\n",
        "  if ret == True:\n",
        "    #frame = np.rot90(frame)\n",
        "    #frame = np.rot90(frame)\n",
        "    #frame = np.rot90(frame)\n",
        "    outputs = predictor(frame)\n",
        "    \n",
        "    v = Visualizer(frame, MetadataCatalog.get(\"coco_2017_val\"), scale=1.5, instance_mode=ColorMode.IMAGE_BW)\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    v = v.get_image()[:, :, ::-1]\n",
        "    cv2.imwrite(storagepath + '/result_%04i.jpg' %i, v )\n",
        "    i+=1\n",
        "    if i == 3:\n",
        "      print(\"Processing the video! Here is a frame:\")\n",
        "      cv2_imshow(v)\n",
        "    \n",
        "  # Break the loop\n",
        "  else:\n",
        "    break \n",
        " \n",
        "# When everything done, release the video capture and video write objects\n",
        "cap.release()\n",
        "# Closes all the frames\n",
        "cv2.destroyAllWindows()\n",
        "print('Done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su9lf3Pgijhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# look at the outputs\n",
        "outputs[\"instances\"].pred_classes\n",
        "outputs[\"instances\"].pred_boxes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qjAzRAqemDr",
        "colab_type": "text"
      },
      "source": [
        "# Additional Keypoint Segmentation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzEZzBmxlDFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check how many frames were processed and stored\n",
        "import os\n",
        "path, dirs, files = next(os.walk(storagepath))\n",
        "frame_count = len(files)\n",
        "print(frame_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaY-dP_ilTua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here you could potentially crop your frames testwise and apply it in the code down below\n",
        "im = cv2.imread(outputpath + \"/result_0000.jpg\")\n",
        "assert not isinstance(im,type(None)), 'image not found'\n",
        "im = im[0:1080, 0:1620]  #Bottom pixel to top pixel;left to right pixel\n",
        "cv2_imshow(im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEjtZgPTegg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"./detectron2_repo/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # set threshold for this model\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x/137849621/model_final_a6e10b.pkl\"\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "import glob\n",
        "i=0\n",
        "for frame in glob.iglob(storagepath + '/*.jpg'):\n",
        "    frame = cv2.imread(frame)\n",
        "    outputs = predictor(frame)\n",
        "    v = Visualizer(frame[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.5)\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    v = v.get_image()[:, :, ::-1]\n",
        "    #v = v[0:1080, 300:1500] #in case you want to crop a video\n",
        "    cv2.imwrite(outputpath + '/result_%04i.jpg' %i, v)                                                     \n",
        "    i+=1\n",
        "    if i == 3:\n",
        "      print('Processing your images!')\n",
        "\n",
        "# Closes all the frames\n",
        "cv2.destroyAllWindows() \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okr2oMZNeyZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# look at the outputs\n",
        "outputs[\"instances\"].pred_classes\n",
        "outputs[\"instances\"].pred_boxes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IRHh1sxvSj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Run this if you want to delete the instance segmented images\n",
        "from shutil import rmtree\n",
        "rmtree(storagepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYdUhZxD0Z3l",
        "colab_type": "text"
      },
      "source": [
        "# Export results as video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOAsACTVz0vM",
        "colab_type": "code",
        "outputId": "ca52b6c8-12b8-49ac-964c-061716cfb175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pathIn= outputpath\n",
        "pathOut = '/content/drive/My Drive/Colab Notebooks/processedVideo.mp4' #Store the final video\n",
        "fps = 20 #change as you wish\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "import glob\n",
        "\n",
        "frame_array = []\n",
        "files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
        "#for sorting the file names properly\n",
        "files.sort(key = lambda x: x[5:-4])\n",
        "files.sort()\n",
        "\n",
        "frame_array = []\n",
        "files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
        "#for sorting the file names properly\n",
        "files.sort(key = lambda x: x[5:-4])\n",
        "for frame in glob.iglob(pathIn + '/*.jpg'):\n",
        "    #reading each files\n",
        "    img = cv2.imread(frame)\n",
        "    height, width, layers = img.shape\n",
        "    size = (width,height)\n",
        "    \n",
        "    #inserting the frames into an image array\n",
        "    frame_array.append(img)\n",
        "out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
        "for i in range(len(frame_array)):\n",
        "    # writing to a image array\n",
        "    out.write(frame_array[i])\n",
        "out.release()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/finalGripper\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
